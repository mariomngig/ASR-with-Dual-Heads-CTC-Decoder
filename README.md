From-Scratch Transformer ASR with Dual Heads (CTC + Decoder)  
-	Developed a Speech Recognition (ASR) system from scratch using PyTorch and the LJSpeech dataset.Developed 
-	Implemented a custom Transformer architecture with a dual-head output: one for Connectionist Temporal Classification (CTC) loss and another for autoregressive decoding, enabling both alignment-free training and sequence modeling.
-	Trained the model from raw audio-text pairs without relying on pretrained models or libraries like Hugging Face
-	Evaluated system performance using standard ASR metrics like Word Error Rate (WER) and character-level decoding.
